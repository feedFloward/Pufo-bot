{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37864bitpufovenvee26a0d988844e00833a0ef8fa7fa7e2",
   "display_name": "Python 3.7.8 64-bit ('.pufo': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./transcripts/117_Atoll.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "total characters : 18627\ntotal vocab: 49\n"
    }
   ],
   "source": [
    "n_chars = len(text)\n",
    "n_vocab = len(chars)\n",
    "print(f\"total characters : {n_chars}\")\n",
    "print(f\"total vocab: {n_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total patterns: 18527\n"
    }
   ],
   "source": [
    "seq_lenth = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_lenth, 1):\n",
    "    seq_in = text[i:i + seq_lenth]\n",
    "    seq_out = text[i + seq_lenth]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(f\"Total patterns: {n_patterns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (n_patterns, seq_lenth, 1))\n",
    "X = X / float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n145/145 [==============================] - ETA: 0s - loss: 3.0981\nEpoch 00001: loss improved from inf to 3.09812, saving model to weights-improvement-01-3.0981.hdf5\n145/145 [==============================] - 86s 594ms/step - loss: 3.0981\nEpoch 2/20\n145/145 [==============================] - ETA: 0s - loss: 3.0453\nEpoch 00002: loss improved from 3.09812 to 3.04533, saving model to weights-improvement-02-3.0453.hdf5\n145/145 [==============================] - 86s 590ms/step - loss: 3.0453\nEpoch 3/20\n145/145 [==============================] - ETA: 0s - loss: 3.0287\nEpoch 00003: loss improved from 3.04533 to 3.02872, saving model to weights-improvement-03-3.0287.hdf5\n145/145 [==============================] - 84s 579ms/step - loss: 3.0287\nEpoch 4/20\n145/145 [==============================] - ETA: 0s - loss: 2.9695\nEpoch 00004: loss improved from 3.02872 to 2.96947, saving model to weights-improvement-04-2.9695.hdf5\n145/145 [==============================] - 84s 578ms/step - loss: 2.9695\nEpoch 5/20\n145/145 [==============================] - ETA: 0s - loss: 2.8834\nEpoch 00005: loss improved from 2.96947 to 2.88344, saving model to weights-improvement-05-2.8834.hdf5\n145/145 [==============================] - 89s 615ms/step - loss: 2.8834\nEpoch 6/20\n145/145 [==============================] - ETA: 0s - loss: 2.8370\nEpoch 00006: loss improved from 2.88344 to 2.83698, saving model to weights-improvement-06-2.8370.hdf5\n145/145 [==============================] - 86s 594ms/step - loss: 2.8370\nEpoch 7/20\n145/145 [==============================] - ETA: 0s - loss: 2.7725\nEpoch 00007: loss improved from 2.83698 to 2.77254, saving model to weights-improvement-07-2.7725.hdf5\n145/145 [==============================] - 87s 601ms/step - loss: 2.7725\nEpoch 8/20\n145/145 [==============================] - ETA: 0s - loss: 2.7024\nEpoch 00008: loss improved from 2.77254 to 2.70236, saving model to weights-improvement-08-2.7024.hdf5\n145/145 [==============================] - 94s 647ms/step - loss: 2.7024\nEpoch 9/20\n145/145 [==============================] - ETA: 0s - loss: 2.6431\nEpoch 00009: loss improved from 2.70236 to 2.64311, saving model to weights-improvement-09-2.6431.hdf5\n145/145 [==============================] - 91s 628ms/step - loss: 2.6431\nEpoch 10/20\n145/145 [==============================] - ETA: 0s - loss: 2.6159\nEpoch 00010: loss improved from 2.64311 to 2.61587, saving model to weights-improvement-10-2.6159.hdf5\n145/145 [==============================] - 88s 609ms/step - loss: 2.6159\nEpoch 11/20\n145/145 [==============================] - ETA: 0s - loss: 2.5980\nEpoch 00011: loss improved from 2.61587 to 2.59800, saving model to weights-improvement-11-2.5980.hdf5\n145/145 [==============================] - 88s 607ms/step - loss: 2.5980\nEpoch 12/20\n145/145 [==============================] - ETA: 0s - loss: 2.5823\nEpoch 00012: loss improved from 2.59800 to 2.58233, saving model to weights-improvement-12-2.5823.hdf5\n145/145 [==============================] - 86s 596ms/step - loss: 2.5823\nEpoch 13/20\n145/145 [==============================] - ETA: 0s - loss: 2.5698\nEpoch 00013: loss improved from 2.58233 to 2.56975, saving model to weights-improvement-13-2.5698.hdf5\n145/145 [==============================] - 64s 440ms/step - loss: 2.5698\nEpoch 14/20\n145/145 [==============================] - ETA: 0s - loss: 2.5552\nEpoch 00014: loss improved from 2.56975 to 2.55522, saving model to weights-improvement-14-2.5552.hdf5\n145/145 [==============================] - 63s 433ms/step - loss: 2.5552\nEpoch 15/20\n145/145 [==============================] - ETA: 0s - loss: 2.5437\nEpoch 00015: loss improved from 2.55522 to 2.54366, saving model to weights-improvement-15-2.5437.hdf5\n145/145 [==============================] - 88s 608ms/step - loss: 2.5437\nEpoch 16/20\n145/145 [==============================] - ETA: 0s - loss: 2.5266\nEpoch 00016: loss improved from 2.54366 to 2.52663, saving model to weights-improvement-16-2.5266.hdf5\n145/145 [==============================] - 71s 489ms/step - loss: 2.5266\nEpoch 17/20\n145/145 [==============================] - ETA: 0s - loss: 2.5172\nEpoch 00017: loss improved from 2.52663 to 2.51718, saving model to weights-improvement-17-2.5172.hdf5\n145/145 [==============================] - 93s 639ms/step - loss: 2.5172\nEpoch 18/20\n145/145 [==============================] - ETA: 0s - loss: 2.4987\nEpoch 00018: loss improved from 2.51718 to 2.49871, saving model to weights-improvement-18-2.4987.hdf5\n145/145 [==============================] - 115s 790ms/step - loss: 2.4987\nEpoch 19/20\n145/145 [==============================] - ETA: 0s - loss: 2.4804\nEpoch 00019: loss improved from 2.49871 to 2.48036, saving model to weights-improvement-19-2.4804.hdf5\n145/145 [==============================] - 138s 953ms/step - loss: 2.4804\nEpoch 20/20\n145/145 [==============================] - ETA: 0s - loss: 2.4648\nEpoch 00020: loss improved from 2.48036 to 2.46477, saving model to weights-improvement-20-2.4648.hdf5\n145/145 [==============================] - 138s 948ms/step - loss: 2.4648\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f1c1033f6d0>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size= 128, callbacks= callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"weights-improvement-20-2.4648.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "ufunc 'true_divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b30e2dfc2466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'true_divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "pattern = \"S\"\n",
    "for i in range(1000):\n",
    "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}